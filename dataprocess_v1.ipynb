{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of De Bondt and Thaler (1985)\n",
    "\n",
    "This notebook is adapted from code written by [Charles Martineau](http://www.charlesmartineau.com/) at the University of Toronto.\n",
    "Prepared by [Vincent Grégoire](http://www.vincentgregoire.com), Department of Finance, The University of Melbourne. \n",
    "\n",
    "Objectives:\n",
    "\n",
    "- Test for the overreaction hypothesis in financial markets based on \n",
    "  [De Bondt and Thaler (1985), Does the Stock Market Overreact?,\n",
    "  Journal of Finance](http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1985.tb05004.x/full).\n",
    "- Get similar results to Figure 3 in the paper.\n",
    "\n",
    "Why:\n",
    "\n",
    "- Research in experimental psychology has suggested that, in violation of\n",
    "  Baye's rule, most people \"overreact\" to unexpected and dramatic news\n",
    "  events. The question then arises whether such behavior matters at the\n",
    "  market level.\n",
    "  \n",
    "This is not meant to be a perfect replication. In fact, I deliberately made different choices in the filtering (number of observations required, listing exchanges, etc.) and in the way to assess performance (computing abnormal returns, forming portfolios, etc.). The goal here is to replicate the spirit, and educate on how one can compute portfolio returns in Python.\n",
    " \n",
    "This notebook was created as supplemental material to a Python for financial research workshop for finance honours and PhD students at the University of Melbourne in March of 2018.\n",
    "\n",
    "Latest version: <https://github.com/vgreg/python-finance-unimelb2018>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: load the CRSP monthly file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WRDS files uses characters (letters such as `C`) to identify special cases. In our case we'll ignore these, but it's good practice to read the dataset documentation carefully to make sure that what you are doing is reasonable.\n",
    "\n",
    "In this case, we reload the file, telling pandas to treat `C` as a null value. We also parse the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>exchcd</th>\n",
       "      <th>permco</th>\n",
       "      <th>prc</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>shrout</th>\n",
       "      <th>vwretd</th>\n",
       "      <th>ewretd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>110.250</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.032732</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.023174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-02-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>102.375</td>\n",
       "      <td>342.0</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-0.033046</td>\n",
       "      <td>-0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>96.500</td>\n",
       "      <td>489.0</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-0.064002</td>\n",
       "      <td>-0.096824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>94.000</td>\n",
       "      <td>249.0</td>\n",
       "      <td>-0.025907</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.037029</td>\n",
       "      <td>0.032975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-05-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>96.250</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966405</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-08-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>5.500</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>-0.087757</td>\n",
       "      <td>-0.085788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966406</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-09-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>5.000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>-0.109718</td>\n",
       "      <td>-0.079025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966407</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-10-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>3.125</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>0.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966408</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-11-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>-0.041046</td>\n",
       "      <td>-0.051395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966409</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-12-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>-0.027005</td>\n",
       "      <td>-0.080744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721955 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        permno       date  exchcd  permco      prc     vol        ret  shrout  \\\n",
       "0        10006 1926-01-30     1.0   22156  110.250   753.0   0.032732   600.0   \n",
       "1        10006 1926-02-27     1.0   22156  102.375   342.0  -0.071429   600.0   \n",
       "2        10006 1926-03-31     1.0   22156   96.500   489.0  -0.042735   600.0   \n",
       "3        10006 1926-04-30     1.0   22156   94.000   249.0  -0.025907   600.0   \n",
       "4        10006 1926-05-28     1.0   22156   96.250    81.0   0.023936   600.0   \n",
       "...        ...        ...     ...     ...      ...     ...        ...     ...   \n",
       "966405   93172 1974-08-30     1.0     699    5.500  1711.0  -0.371429  2495.0   \n",
       "966406   93172 1974-09-30     1.0     699    5.000   582.0  -0.090909  2495.0   \n",
       "966407   93172 1974-10-31     1.0     699    3.125  1137.0  -0.375000  2495.0   \n",
       "966408   93172 1974-11-29     1.0     699    2.625  1031.0  -0.160000  2929.0   \n",
       "966409   93172 1974-12-31     1.0     699    1.750  1643.0  -0.333333  2929.0   \n",
       "\n",
       "          vwretd    ewretd  \n",
       "0       0.000561  0.023174  \n",
       "1      -0.033046 -0.053510  \n",
       "2      -0.064002 -0.096824  \n",
       "3       0.037029  0.032975  \n",
       "4       0.012095  0.001035  \n",
       "...          ...       ...  \n",
       "966405 -0.087757 -0.085788  \n",
       "966406 -0.109718 -0.079025  \n",
       "966407  0.165584  0.088877  \n",
       "966408 -0.041046 -0.051395  \n",
       "966409 -0.027005 -0.080744  \n",
       "\n",
       "[721955 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crsp = pd.read_csv(r'C:\\Users\\10317\\Desktop\\kw4smgwgvkezomgo.csv.gz', na_values=['C'], parse_dates=['date'])\n",
    "\n",
    "# The output from WRDS returns a mixed of small and large cap column names.\n",
    "# We can easily convert everything to small caps.\n",
    "cols = df_crsp.columns\n",
    "df_crsp.columns = [c.lower() for c in cols]\n",
    "df_crsp.drop_duplicates(keep='first',inplace=True)\n",
    "df_crsp.dropna(inplace=True)\n",
    "df_crsp.reset_index(inplace=True,drop=True)\n",
    "df_crsp = df_crsp[df_crsp['exchcd'] == 1.0]\n",
    "df_crsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1926 = df_crsp[df_crsp['date'].dt.year == 1926]  # 筛选出1926年的数据,这一步是在check有多少上市公司\n",
    "# 根据 permno 去重，统计公司数量\n",
    "unique_companies = data_1926['permno'].nunique()\n",
    "unique_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>exchcd</th>\n",
       "      <th>permco</th>\n",
       "      <th>prc</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>shrout</th>\n",
       "      <th>vwretd</th>\n",
       "      <th>ewretd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>110.250</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.032732</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.023174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-02-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>102.375</td>\n",
       "      <td>342.0</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-0.033046</td>\n",
       "      <td>-0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>96.500</td>\n",
       "      <td>489.0</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-0.064002</td>\n",
       "      <td>-0.096824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>94.000</td>\n",
       "      <td>249.0</td>\n",
       "      <td>-0.025907</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.037029</td>\n",
       "      <td>0.032975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006</td>\n",
       "      <td>1926-05-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22156</td>\n",
       "      <td>96.250</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966405</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-08-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>5.500</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>-0.087757</td>\n",
       "      <td>-0.085788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966406</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-09-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>5.000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>-0.109718</td>\n",
       "      <td>-0.079025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966407</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-10-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>3.125</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>0.165584</td>\n",
       "      <td>0.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966408</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-11-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>-0.041046</td>\n",
       "      <td>-0.051395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966409</th>\n",
       "      <td>93172</td>\n",
       "      <td>1974-12-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>-0.027005</td>\n",
       "      <td>-0.080744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721955 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        permno       date  exchcd  permco      prc     vol        ret  shrout  \\\n",
       "0        10006 1926-01-30     1.0   22156  110.250   753.0   0.032732   600.0   \n",
       "1        10006 1926-02-27     1.0   22156  102.375   342.0  -0.071429   600.0   \n",
       "2        10006 1926-03-31     1.0   22156   96.500   489.0  -0.042735   600.0   \n",
       "3        10006 1926-04-30     1.0   22156   94.000   249.0  -0.025907   600.0   \n",
       "4        10006 1926-05-28     1.0   22156   96.250    81.0   0.023936   600.0   \n",
       "...        ...        ...     ...     ...      ...     ...        ...     ...   \n",
       "966405   93172 1974-08-30     1.0     699    5.500  1711.0  -0.371429  2495.0   \n",
       "966406   93172 1974-09-30     1.0     699    5.000   582.0  -0.090909  2495.0   \n",
       "966407   93172 1974-10-31     1.0     699    3.125  1137.0  -0.375000  2495.0   \n",
       "966408   93172 1974-11-29     1.0     699    2.625  1031.0  -0.160000  2929.0   \n",
       "966409   93172 1974-12-31     1.0     699    1.750  1643.0  -0.333333  2929.0   \n",
       "\n",
       "          vwretd    ewretd  \n",
       "0       0.000561  0.023174  \n",
       "1      -0.033046 -0.053510  \n",
       "2      -0.064002 -0.096824  \n",
       "3       0.037029  0.032975  \n",
       "4       0.012095  0.001035  \n",
       "...          ...       ...  \n",
       "966405 -0.087757 -0.085788  \n",
       "966406 -0.109718 -0.079025  \n",
       "966407  0.165584  0.088877  \n",
       "966408 -0.041046 -0.051395  \n",
       "966409 -0.027005 -0.080744  \n",
       "\n",
       "[721955 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crsp['prc'] = abs(df_crsp['prc'])#取绝对值\n",
    "df_crsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2： 筛选出不同时间点所对应的符合条件的流动性ok的股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "起始日期:1926-01-01,符合要求公司比例: 70.91%,符合要求公司总数: 351, 有效公司总数: 495\n",
      "起始日期:1929-01-01,符合要求公司比例: 72.57%,符合要求公司总数: 455, 有效公司总数: 627\n",
      "起始日期:1932-01-01,符合要求公司比例: 83.79%,符合要求公司总数: 610, 有效公司总数: 728\n",
      "起始日期:1935-01-01,符合要求公司比例: 91.51%,符合要求公司总数: 647, 有效公司总数: 707\n",
      "起始日期:1938-01-01,符合要求公司比例: 96.04%,符合要求公司总数: 751, 有效公司总数: 782\n",
      "起始日期:1941-01-01,符合要求公司比例: 97.22%,符合要求公司总数: 769, 有效公司总数: 791\n",
      "起始日期:1944-01-01,符合要求公司比例: 97.91%,符合要求公司总数: 795, 有效公司总数: 812\n",
      "起始日期:1947-01-01,符合要求公司比例: 99.34%,符合要求公司总数: 902, 有效公司总数: 908\n",
      "起始日期:1950-01-01,符合要求公司比例: 98.48%,符合要求公司总数: 973, 有效公司总数: 988\n",
      "起始日期:1953-01-01,符合要求公司比例: 97.80%,符合要求公司总数: 1022, 有效公司总数: 1045\n",
      "起始日期:1956-01-01,符合要求公司比例: 96.87%,符合要求公司总数: 1020, 有效公司总数: 1053\n",
      "起始日期:1959-01-01,符合要求公司比例: 95.31%,符合要求公司总数: 1016, 有效公司总数: 1066\n",
      "起始日期:1962-01-01,符合要求公司比例: 96.23%,符合要求公司总数: 1098, 有效公司总数: 1141\n",
      "起始日期:1965-01-01,符合要求公司比例: 97.79%,符合要求公司总数: 1196, 有效公司总数: 1223\n",
      "起始日期:1968-01-01,符合要求公司比例: 98.22%,符合要求公司总数: 1216, 有效公司总数: 1238\n",
      "起始日期:1971-01-01,符合要求公司比例: 94.21%,符合要求公司总数: 1252, 有效公司总数: 1329\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 假设 new_data 已经加载，并确保 'date' 列是 datetime 类型\n",
    "df_crsp['date'] = pd.to_datetime(df_crsp['date'])  # 确保日期是datetime格式\n",
    "#new_data['date'] = pd.to_datetime(new_data['date'])  # 确保日期是datetime格式\n",
    "# 初始起始年份和月份\n",
    "start_year = 1926\n",
    "start_month = 1\n",
    "\n",
    "# 初始化变量\n",
    "date = []\n",
    "valid_firm_number = []\n",
    "total_number = []\n",
    "filter_all_data = defaultdict(list)\n",
    "# 进行16次循环，每次起始时间向后增加3年\n",
    "for i in range(16):\n",
    "    sum_valid = 0  # 累计连续85个月的次数\n",
    "    total_tests = 0  # 总的测试次数\n",
    "    # 计算当前循环的起始时间\n",
    "    start_date = pd.Timestamp(year=start_year + i * 3, month=start_month, day=1)\n",
    "    end_date = start_date + pd.DateOffset(months=85)  # 85个月的截止时间\n",
    "\n",
    "    #print(f\"\\n第 {i+1} 次测试: 起始时间 {start_date.date()}\")\n",
    "    date.append(start_date.date())\n",
    "\n",
    "    # 筛选在当前时间范围内的数据\n",
    "    filtered_data = df_crsp[(df_crsp['date']>= start_date)]\n",
    "    #filtered_data = new_data[(new_data['date']>= start_date)]\n",
    "    grouped_data = filtered_data.groupby('permno').filter(lambda x: (x['date'].iloc[0].year == start_date.year) and (x['date'].iloc[0].month == start_date.month))\n",
    "    grouped_data = grouped_data.groupby('permno')  # 再次按 permno 分组\n",
    "\n",
    "    # 遍历每个分组，判断前85个月的连续性\n",
    "    for idx, group in grouped_data:\n",
    "        total_tests += 1  # 统计总测试次数  \n",
    "\n",
    "        # 提取当前分组前85个月的数据\n",
    "        first_85 = group.head(85).copy()\n",
    "        #print(first_85.head())        \n",
    "        first_85['year'] = first_85['date'].dt.year\n",
    "        first_85['month'] = first_85['date'].dt.month\n",
    "        first_85['month_number'] = (first_85['year'] - first_85['year'].iloc[0]) * 12 + first_85['month']\n",
    "\n",
    "        # 判断连续性\n",
    "        first_85['month_diff'] = first_85['month_number'].diff().fillna(1)\n",
    "        first_85['is_consecutive'] = first_85['month_diff'] == 1\n",
    "\n",
    "        if first_85['is_consecutive'].all():\n",
    "            #print(f\"permno {idx}: 前85个月的数据是连续的。\")\n",
    "            sum_valid += 1\n",
    "            filter_all_data[start_date.date()].append(idx)\n",
    "        #else:\n",
    "            #print(f\"permno {idx}: 前85个月的数据存在中断。\")\n",
    "    valid_firm_number.append(sum_valid)\n",
    "    total_number.append(total_tests)\n",
    "\n",
    "# 计算并输出结果\n",
    "for i in range(16):\n",
    "    print(f\"起始日期:{date[i]},符合要求公司比例: {valid_firm_number[i] / total_number[i]:.2%},符合要求公司总数: {valid_firm_number[i]}, 有效公司总数: {total_number[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10030,\n",
       " 10049,\n",
       " 10057,\n",
       " 10065,\n",
       " 10081,\n",
       " 10102,\n",
       " 10110,\n",
       " 10129,\n",
       " 10137,\n",
       " 10145,\n",
       " 10188,\n",
       " 10196,\n",
       " 10209,\n",
       " 10217,\n",
       " 10225,\n",
       " 10233,\n",
       " 10241,\n",
       " 10268,\n",
       " 10305,\n",
       " 10313,\n",
       " 10321,\n",
       " 10356,\n",
       " 10364,\n",
       " 10372,\n",
       " 10399,\n",
       " 10401,\n",
       " 10428,\n",
       " 10436,\n",
       " 10444,\n",
       " 10460,\n",
       " 10487,\n",
       " 10495,\n",
       " 10516,\n",
       " 10524,\n",
       " 10559,\n",
       " 10575,\n",
       " 10583,\n",
       " 10591,\n",
       " 10604,\n",
       " 10612,\n",
       " 10647,\n",
       " 10655,\n",
       " 10671,\n",
       " 10698,\n",
       " 10719,\n",
       " 10743,\n",
       " 10751,\n",
       " 10778,\n",
       " 10786,\n",
       " 10794,\n",
       " 10858,\n",
       " 10874,\n",
       " 10890,\n",
       " 10911,\n",
       " 10938,\n",
       " 10946,\n",
       " 10954,\n",
       " 10970,\n",
       " 10989,\n",
       " 10997,\n",
       " 11009,\n",
       " 11025,\n",
       " 11033,\n",
       " 11041,\n",
       " 11068,\n",
       " 11092,\n",
       " 11105,\n",
       " 11113,\n",
       " 11121,\n",
       " 11148,\n",
       " 11156,\n",
       " 11164,\n",
       " 11172,\n",
       " 11199,\n",
       " 11201,\n",
       " 11252,\n",
       " 11260,\n",
       " 11287,\n",
       " 11295,\n",
       " 11308,\n",
       " 11324,\n",
       " 11340,\n",
       " 11359,\n",
       " 11367,\n",
       " 11391,\n",
       " 11404,\n",
       " 11412,\n",
       " 11447,\n",
       " 11463,\n",
       " 11471,\n",
       " 11498,\n",
       " 11500,\n",
       " 11535,\n",
       " 11543,\n",
       " 11551,\n",
       " 11594,\n",
       " 11607,\n",
       " 11615,\n",
       " 11623,\n",
       " 11658,\n",
       " 11666,\n",
       " 11674,\n",
       " 11682,\n",
       " 11690,\n",
       " 11703,\n",
       " 11711,\n",
       " 11746,\n",
       " 11754,\n",
       " 11762,\n",
       " 11789,\n",
       " 11818,\n",
       " 11834,\n",
       " 11850,\n",
       " 11877,\n",
       " 11885,\n",
       " 11914,\n",
       " 11922,\n",
       " 11930,\n",
       " 11949,\n",
       " 11957,\n",
       " 11965,\n",
       " 11973,\n",
       " 11981,\n",
       " 12001,\n",
       " 12028,\n",
       " 12036,\n",
       " 12060,\n",
       " 12079,\n",
       " 12087,\n",
       " 12095,\n",
       " 12108,\n",
       " 12116,\n",
       " 12124,\n",
       " 12132,\n",
       " 12140,\n",
       " 12159,\n",
       " 12167,\n",
       " 12175,\n",
       " 12183,\n",
       " 12191,\n",
       " 12255,\n",
       " 12263,\n",
       " 12335,\n",
       " 12343,\n",
       " 12351,\n",
       " 12378,\n",
       " 12386,\n",
       " 12394,\n",
       " 12407,\n",
       " 12431,\n",
       " 12458,\n",
       " 12466,\n",
       " 12482,\n",
       " 12503,\n",
       " 12511,\n",
       " 12546,\n",
       " 12570,\n",
       " 12589,\n",
       " 12597,\n",
       " 12626,\n",
       " 12634,\n",
       " 12642,\n",
       " 12669,\n",
       " 12685,\n",
       " 12706,\n",
       " 12714,\n",
       " 12730,\n",
       " 12749,\n",
       " 12765,\n",
       " 12802,\n",
       " 12810,\n",
       " 12837,\n",
       " 12845,\n",
       " 12888,\n",
       " 12896,\n",
       " 12909,\n",
       " 12941,\n",
       " 12968,\n",
       " 12976,\n",
       " 12984,\n",
       " 12992,\n",
       " 13012,\n",
       " 13020,\n",
       " 13039,\n",
       " 13047,\n",
       " 13063,\n",
       " 13071,\n",
       " 13098,\n",
       " 13100,\n",
       " 13119,\n",
       " 13143,\n",
       " 13151,\n",
       " 13178,\n",
       " 13207,\n",
       " 13215,\n",
       " 13258,\n",
       " 13266,\n",
       " 13274,\n",
       " 13290,\n",
       " 13311,\n",
       " 13354,\n",
       " 13370,\n",
       " 13389,\n",
       " 13434,\n",
       " 13442,\n",
       " 13469,\n",
       " 13477,\n",
       " 13485,\n",
       " 13514,\n",
       " 13522,\n",
       " 13549,\n",
       " 13557,\n",
       " 13565,\n",
       " 13573,\n",
       " 13610,\n",
       " 13629,\n",
       " 13645,\n",
       " 13661,\n",
       " 13688,\n",
       " 13717,\n",
       " 13733,\n",
       " 13741,\n",
       " 13768,\n",
       " 13784,\n",
       " 13792,\n",
       " 13805,\n",
       " 13813,\n",
       " 13872,\n",
       " 13928,\n",
       " 13952,\n",
       " 13979,\n",
       " 14007,\n",
       " 14015,\n",
       " 14031,\n",
       " 14058,\n",
       " 14066,\n",
       " 14074,\n",
       " 14082,\n",
       " 14090,\n",
       " 14103,\n",
       " 14111,\n",
       " 14146,\n",
       " 14154,\n",
       " 14162,\n",
       " 14189,\n",
       " 14218,\n",
       " 14234,\n",
       " 14242,\n",
       " 14250,\n",
       " 14269,\n",
       " 14277,\n",
       " 14285,\n",
       " 14293,\n",
       " 14306,\n",
       " 14314,\n",
       " 14322,\n",
       " 14330,\n",
       " 14349,\n",
       " 14357,\n",
       " 14373,\n",
       " 14381,\n",
       " 14402,\n",
       " 14410,\n",
       " 14429,\n",
       " 14437,\n",
       " 14445,\n",
       " 14453,\n",
       " 14461,\n",
       " 14488,\n",
       " 14496,\n",
       " 14509,\n",
       " 14525,\n",
       " 14533,\n",
       " 14541,\n",
       " 14568,\n",
       " 14576,\n",
       " 14592,\n",
       " 14605,\n",
       " 14613,\n",
       " 14621,\n",
       " 14648,\n",
       " 14664,\n",
       " 14672,\n",
       " 14680,\n",
       " 14699,\n",
       " 14736,\n",
       " 14752,\n",
       " 14760,\n",
       " 14779,\n",
       " 14787,\n",
       " 14795,\n",
       " 14808,\n",
       " 14824,\n",
       " 14859,\n",
       " 14867,\n",
       " 14883,\n",
       " 14891,\n",
       " 14904,\n",
       " 14912,\n",
       " 14947,\n",
       " 14955,\n",
       " 14963,\n",
       " 14998,\n",
       " 15042,\n",
       " 15050,\n",
       " 15069,\n",
       " 15077,\n",
       " 15085,\n",
       " 15093,\n",
       " 15106,\n",
       " 15114,\n",
       " 15122,\n",
       " 15149,\n",
       " 15157,\n",
       " 15210,\n",
       " 15229,\n",
       " 15237,\n",
       " 15245,\n",
       " 15261,\n",
       " 15288,\n",
       " 15309,\n",
       " 15317,\n",
       " 15325,\n",
       " 15341,\n",
       " 15368,\n",
       " 15376,\n",
       " 15392,\n",
       " 15405,\n",
       " 15413,\n",
       " 15421,\n",
       " 15448,\n",
       " 15456,\n",
       " 15464,\n",
       " 15472,\n",
       " 15499,\n",
       " 15528,\n",
       " 15560,\n",
       " 15755,\n",
       " 15800,\n",
       " 16109,\n",
       " 16280,\n",
       " 19318,\n",
       " 19473,\n",
       " 24475,\n",
       " 25435,\n",
       " 25486,\n",
       " 25566,\n",
       " 27561,\n",
       " 27692,\n",
       " 28513,\n",
       " 58368]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以通过如下方式筛选出不同起始点所对应的满足连续85个月都有数值的要求的股票，数字为代码 permno\n",
    "filter_all_data[pd.to_datetime('1926-01-01').date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index (to select easily on date)\n",
    "df_crsp = df_crsp.set_index('date')\n",
    "df_crsp = df_crsp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data cleaning\n",
    "\n",
    "# We can drop SHRCD and EXCHCD, we already the filtering.\n",
    "del df_crsp['shrcd']\n",
    "del df_crsp['exchcd']\n",
    "# Drop obs with missing returns\n",
    "df_crsp = df_crsp[df_crsp.ret.notnull()]\n",
    "\n",
    "# There are some negative number in the PRC column. Why is that? To find out, look at the doc!\n",
    "# In our case, (in most cases actually), it's ok to just take the absolute value.\n",
    "df_crsp['prc'] = np.abs(df_crsp['prc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute continuously compounded returns (i.e. log returns).\n",
    "# Why are these useful?\n",
    "df_crsp['lret'] = np.log(1 + df_crsp['ret'])\n",
    "df_crsp['lvwretd'] = np.log(1 + df_crsp['vwretd'])\n",
    "df_crsp['lewretd'] = np.log(1 + df_crsp['ewretd'])\n",
    "\n",
    "# Compute the market cap\n",
    "df_crsp['size'] = df_crsp['shrout'] * df_crsp['prc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the average size over time\n",
    "df_crsp.groupby(['date'])['size'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total market size over time\n",
    "\n",
    "ax = df_crsp.groupby(['date'])['size'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More informative in logs!\n",
    "ax = df_crsp.groupby(['date'])['size'].sum().plot(logy=True)\n",
    "\n",
    "# Add some informative lines\n",
    "ax.axvline(x=datetime(1929,10,24), color='k', linestyle=':') # Black Monday\n",
    "ax.axvline(x=datetime(1987,10,19), color='k', linestyle=':') # Black Monday again\n",
    "ax.axvline(x=datetime(2001,1,1), color='k', linestyle=':') # Tech bubble burst\n",
    "ax.axvline(x=datetime(2008,9,16), color='k', linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: analysis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "form_period = 36 # Formation period, in month\n",
    "hold_period = 36 # Holding period, in months\n",
    "use_deciles = True # Use deciles to form the top and bottom portfolio\n",
    "n_stocks = 35  # Number of stocks in the top and bottom performance (if not using top and bottom deciles)\n",
    "start_date = '1935-01-01'\n",
    "end_date = '2014-01-01'\n",
    "benchmark = 'vwretd' # Benchmark market return to use ('vwretd' or 'ewretd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dates of portfolio formation.\n",
    "# The frequency tells how far appart to put the dates.\n",
    "# 'M' stand for month, 'MS' is for month start, to make sure we \n",
    "# have first day of the month. It needs to be a string, so we convert\n",
    "# our numbers to string. Note: you can also keep floats and use pandas\n",
    "# date offsets.\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq=str(np.int(form_period)) + 'MS')\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: forming portfolios\n",
    "\n",
    "In this step, we want to create the portfolios at each portfolio formation date. Basically, we want to evaluate each stock's performance in the formation period prior to the formation date, and form portfolios (groups of stocks) based on past performance.\n",
    "\n",
    "For simplicity, at each date we only keep track of the top and bottom portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first do it for only one date.\n",
    "date = dates[0]\n",
    "\n",
    "beg_dt = date - pd.offsets.MonthBegin(1) * form_period\n",
    "\n",
    "# Select obs for the formation period\n",
    "crsp_t = df_crsp[beg_dt:date.to_pydatetime()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to keep stocks that are there during the full formation window\n",
    "\n",
    "crsp_t['N'] = crsp_t.groupby(['permno'])['permno'].transform('count')\n",
    "\n",
    "# Filter on number of observations. We only keep sotcks for which we have returns\n",
    "# over the full observation period.\n",
    "crsp_t = crsp_t[crsp_t['N'] >= form_period]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each stock we want to compute the full period return. Easy with log returns, just sum up!\n",
    "stock_ret = crsp_t.groupby('permno')['lret', 'lvwretd', 'lewretd'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next compute excess returns based on the chosen index.\n",
    "# Note that since the benchmark is the same for all stocks, we could use\n",
    "# actual returns for ranking purposes. It would only make a difference in some\n",
    "# cases. Which ones?\n",
    "\n",
    "stock_ret['lexret'] = stock_ret['lret'] - stock_ret['l' + benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now deciles and rankings.\n",
    "\n",
    "stock_ret['decile'] = pd.qcut(stock_ret['lexret'], 10, labels=False) # (0=worst, 9=best)\n",
    "stock_ret['rank_asc'] = stock_ret['lexret'].rank() # (1 = worst return)\n",
    "stock_ret['rank_inv'] = stock_ret['lexret'].rank(ascending=False) # (1= best return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign stock to top or bottom portfolio\n",
    "\n",
    "if use_deciles:\n",
    "    top_ptf = stock_ret[stock_ret.decile == 9].reset_index()[['permno', 'lexret']]\n",
    "    bot_ptf = stock_ret[stock_ret.decile == 0].reset_index()[['permno', 'lexret']]\n",
    "else:\n",
    "    top_ptf = stock_ret[stock_ret.rank_inv <= n_stocks].reset_index()[['permno', 'lexret']]\n",
    "    bot_ptf = stock_ret[stock_ret.rank_asc <= n_stocks].reset_index()[['permno', 'lexret']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ptf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_ptf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the code working for one date, we need to run it on each date. Now it's time to make it a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_portfolios(date, df, form_period=36, use_deciles=True, n_stocks=35,\n",
    "                                   benchmark='vwretd'):\n",
    "    beg_dt = date - pd.offsets.MonthBegin(1) * form_period\n",
    "\n",
    "    # Select obs for the formation period\n",
    "    crsp_t = df[beg_dt:date.to_pydatetime()].copy()\n",
    "    \n",
    "    # We only want to keep stocks that are there during the full formation window\n",
    "    crsp_t['N'] = crsp_t.groupby(['permno'])['permno'].transform('count')\n",
    "    # Filter on number of observations. We only keep sotcks for which we have returns\n",
    "    # over the full observation period.\n",
    "    crsp_t = crsp_t[crsp_t['N'] >= form_period]\n",
    "    \n",
    "    # Now for each stock we want to compute the full period return. Easy with log returns, just sum up!\n",
    "    stock_ret = crsp_t.groupby('permno')['lret', 'lvwretd', 'lewretd'].sum()# Next compute excess returns based on the chosen index.\n",
    "    # Compute excess returns\n",
    "    stock_ret['lexret'] = stock_ret['lret'] - stock_ret['l' + benchmark]\n",
    "    # Now deciles and rankings.\n",
    "    stock_ret['decile'] = pd.qcut(stock_ret['lexret'], 10, labels=False) # (0=worst, 9=best)\n",
    "    stock_ret['rank_asc'] = stock_ret['lexret'].rank() # (1 = worst return)\n",
    "    stock_ret['rank_inv'] = stock_ret['lexret'].rank(ascending=False) # (1= best return)\n",
    "    # Assign stock to top or bottom portfolio\n",
    "    if use_deciles:\n",
    "        top_ptf = stock_ret[stock_ret.decile == 9].reset_index()[['permno', 'lexret']]\n",
    "        bot_ptf = stock_ret[stock_ret.decile == 0].reset_index()[['permno', 'lexret']]\n",
    "    else:\n",
    "        top_ptf = stock_ret[stock_ret.rank_inv <= n_stocks].reset_index()[['permno', 'lexret']]\n",
    "        bot_ptf = stock_ret[stock_ret.rank_asc <= n_stocks].reset_index()[['permno', 'lexret']]\n",
    "    \n",
    "    return (bot_ptf, top_ptf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = {}\n",
    "for date in dates:\n",
    "    portfolios[date] = compute_performance_portfolios(date, df_crsp, use_deciles=False, benchmark='vwretd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios[date][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: holding period returns\n",
    "\n",
    "Next, we want to compute cumulative abnormal returns for portfolios during the holding period. We will use the same approach, i.e. do it for one portfolio/date, then package it as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = dates[0]\n",
    "ptf = portfolios[date][0] # Bottom portfolio.\n",
    "\n",
    "benchmark = 'vwretd'\n",
    "weighting = 'vw' # 'vw' or 'ew'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf = ptf.copy()\n",
    "end_dt = date + pd.offsets.MonthBegin(1) * hold_period\n",
    "\n",
    "# Select obs for the formation period\n",
    "crsp_t2 = df_crsp[date.to_pydatetime():end_dt].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with stocks in portfolios, to keep only those stocks\n",
    "crsp_t2 = pd.merge(crsp_t2.reset_index(), ptf, on=['permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make sure we have one observation for each stock/date.\n",
    "# If a stock is delisted, its returns will be 0 after it disappears,\n",
    "# so we just fill in these missing values.\n",
    "# Note that here we're simplifying a bit. CRSP does include delisting\n",
    "# returns that we should have added as well, but we didn't.\n",
    "\n",
    "# The idea here is to create a DataFrame with all the permno/date pairs\n",
    "# that we want in the final dataset. Then we merge that list with the\n",
    "# dataset using \"outer\" which will generate missing values for the\n",
    "# pairs that are not in the dataset.\n",
    "\n",
    "# Get the dates in the dataset.\n",
    "pairs_t2 = [{'date': d, 'permno': p} for d in crsp_t2['date'].unique() \n",
    "                                    for p in ptf['permno'].unique()]\n",
    "pairs_t2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_t2 = pd.DataFrame(pairs_t2)\n",
    "pairs_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to generate placeholders\n",
    "\n",
    "crsp_t2 = pd.merge(crsp_t2, pairs_t2, how='outer',\n",
    "                   on=['permno', 'date'])\n",
    "crsp_t2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_cols = ['ret', 'vwretd', 'ewretd', 'lvwretd','lewretd', 'lret', 'lexret']\n",
    "crsp_t2[ret_cols] = crsp_t2[ret_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want the return up to each point in time\n",
    "crsp_t2['lcumret'] = crsp_t2.groupby('permno')['lret'].cumsum()\n",
    "crsp_t2['lcum' + benchmark] = crsp_t2.groupby('permno')['l' + benchmark].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At each point in time, the return of the portfolio will be the \n",
    "# cumulative return of each component weighted by the initial weight.\n",
    "# Note that here we need the simple return average, not log return.\n",
    "crsp_t2['cumret'] = np.exp(crsp_t2['lcumret']) - 1\n",
    "crsp_t2['cum' + benchmark] = np.exp(crsp_t2['lcum' + benchmark]) - 1\n",
    "\n",
    "# Add weights, equal weighted is easy.\n",
    "ptf['ew'] = 1 / len(ptf)\n",
    "\n",
    "# For value-weighted, need to get size as of formation date.\n",
    "ptf['date'] = date\n",
    "weights = pd.merge_asof(ptf, df_crsp[['permno', 'size']],\n",
    "                        by='permno',\n",
    "                        left_on='date',\n",
    "                        right_index=True)\n",
    "weights['vw'] = weights['size'] / weights['size'].sum()\n",
    "\n",
    "del weights['lexret']\n",
    "del weights['date']\n",
    "del weights['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge back with returns\n",
    "crsp_t2 = pd.merge(crsp_t2, weights, on='permno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute the weighted cumulative return\n",
    "crsp_t2['wcumret'] = crsp_t2[weighting] * crsp_t2['cumret']\n",
    "crsp_t2['wcum' + benchmark] = crsp_t2[weighting] * crsp_t2['cum' + benchmark]\n",
    "\n",
    "ptf_ret = crsp_t2.groupby(['date'])[['wcumret', 'wcum' + benchmark]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the months\n",
    "ptf_ret = ptf_ret.reset_index()\n",
    "ptf_ret['months'] = ptf_ret.index.values + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf_ret['exret'] = ptf_ret['wcumret'] - ptf_ret['wcum' + benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf_ret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks like we're ready to package as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_holding_returns(date, ptf, df, benchmark='vwretd', weighting='vw', hold_per=36):\n",
    "    ptf = ptf.copy()\n",
    "    end_dt = date + pd.offsets.MonthBegin(1) * hold_period\n",
    "    # Select obs for the formation period\n",
    "    crsp_t2 = df[date.to_pydatetime():end_dt].copy()\n",
    "    # Merge with stocks in portfolios, to keep only those stocks\n",
    "    crsp_t2 = pd.merge(crsp_t2.reset_index(), ptf, on=['permno'])\n",
    "    \n",
    "\n",
    "    # Get the dates in the dataset.\n",
    "    pairs_t2 = [{'date': d, 'permno': p} for d in crsp_t2['date'].unique() \n",
    "                                        for p in ptf['permno'].unique()]\n",
    "    pairs_t2 = pd.DataFrame(pairs_t2)\n",
    "    crsp_t2 = pd.merge(crsp_t2, pairs_t2, how='outer',\n",
    "                   on=['permno', 'date'])\n",
    "    ret_cols = ['ret', 'vwretd', 'ewretd', 'lvwretd','lewretd', 'lret', 'lexret']\n",
    "    crsp_t2[ret_cols] = crsp_t2[ret_cols].fillna(0.0)\n",
    "    \n",
    "    # Now we want the return up to each point in time\n",
    "    crsp_t2['lcumret'] = crsp_t2.groupby('permno')['lret'].cumsum()\n",
    "    crsp_t2['lcum' + benchmark] = crsp_t2.groupby('permno')['l' + benchmark].cumsum()\n",
    "\n",
    "    # At each point in time, the return of the portfolio will be the \n",
    "    # cumulative return of each component weighted by the initial weight.\n",
    "    # Note that here we need the simple return average, not log return.\n",
    "    crsp_t2['cumret'] = np.exp(crsp_t2['lcumret']) - 1\n",
    "    crsp_t2['cum' + benchmark] = np.exp(crsp_t2['lcum' + benchmark]) - 1\n",
    "\n",
    "    # Add weights, equal weighted is easy.\n",
    "    ptf['ew'] = 1 / len(ptf)\n",
    "\n",
    "    # For value-weighted, need to get size as of formation date.\n",
    "    ptf['date'] = date\n",
    "    weights = pd.merge_asof(ptf, df_crsp[['permno', 'size']],\n",
    "                            by='permno',\n",
    "                            left_on='date',\n",
    "                            right_index=True)\n",
    "    weights['vw'] = weights['size'] / weights['size'].sum()\n",
    "\n",
    "    del weights['lexret']\n",
    "    del weights['date']\n",
    "    del weights['size']\n",
    "    \n",
    "    # Now merge back with returns\n",
    "    crsp_t2 = pd.merge(crsp_t2, weights, on='permno')\n",
    "    \n",
    "    # Now compute the weighted cumulative return\n",
    "    crsp_t2['wcumret'] = crsp_t2[weighting] * crsp_t2['cumret']\n",
    "    crsp_t2['wcum' + benchmark] = crsp_t2[weighting] * crsp_t2['cum' + benchmark]\n",
    "\n",
    "    ptf_ret = crsp_t2.groupby(['date'])[['wcumret', 'wcum' + benchmark]].sum()\n",
    "    \n",
    "    # Count the months\n",
    "    ptf_ret = ptf_ret.reset_index()\n",
    "    ptf_ret['months'] = ptf_ret.index.values + 1\n",
    "    \n",
    "    ptf_ret['exret'] = ptf_ret['wcumret'] - ptf_ret['wcum' + benchmark]\n",
    "    \n",
    "    return ptf_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_ptf_ret = []\n",
    "top_ptf_ret = []\n",
    "\n",
    "for date in dates:\n",
    "    bot_ptf_ret.append(compute_holding_returns(date, portfolios[date][0], df_crsp,\n",
    "                                               benchmark='vwretd', weighting='vw'))\n",
    "    top_ptf_ret.append(compute_holding_returns(date, portfolios[date][1], df_crsp,\n",
    "                                               benchmark='vwretd', weighting='vw'))\n",
    "    \n",
    "bot_ptf_ret = pd.concat(bot_ptf_ret)\n",
    "top_ptf_ret = pd.concat(top_ptf_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = bot_ptf_ret.groupby('months')['exret'].mean().plot(label='Past losers')\n",
    "top_ptf_ret.groupby('months')['exret'].mean().plot(ax=ax, label='Past winners')\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', alpha=0.5, linestyle=':')\n",
    "ax.axvline(x=12, color='black', alpha=0.5, linestyle='-')\n",
    "ax.axvline(x=24, color='black', alpha=0.5, linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only pre 1980\n",
    "ax = bot_ptf_ret.set_index('date')[:'1980'].groupby('months')['exret'].mean().plot(label='Past losers')\n",
    "top_ptf_ret.set_index('date')[:'1980'].groupby('months')['exret'].mean().plot(ax=ax, label='Past winners')\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', alpha=0.5, linestyle=':')\n",
    "ax.axvline(x=12, color='black', alpha=0.5, linestyle='-')\n",
    "ax.axvline(x=24, color='black', alpha=0.5, linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only post 1980\n",
    "ax = bot_ptf_ret.set_index('date')['1980':].groupby('months')['exret'].mean().plot(label='Past losers')\n",
    "top_ptf_ret.set_index('date')['1980':].groupby('months')['exret'].mean().plot(ax=ax, label='Past winners')\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='black', alpha=0.5, linestyle=':')\n",
    "ax.axvline(x=12, color='black', alpha=0.5, linestyle='-')\n",
    "ax.axvline(x=24, color='black', alpha=0.5, linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: check if the results chnage significantly if portfolio formation is not done in January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
